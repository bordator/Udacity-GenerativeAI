{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9d6626",
   "metadata": {},
   "source": [
    "# Steps 3 & 4: Querying a Completion Model with a Custom Text Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0478d18",
   "metadata": {},
   "source": [
    "Add your API key to the cell below then run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186b2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa50906",
   "metadata": {},
   "source": [
    "The code below loads in the data sorted by cosine distance that you previously created. Run it as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd3a3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The confirmed death toll in Turkey was 53,537;...</td>\n",
       "      <td>[ 0.00134106 -0.02500695 -0.01328005 ...  0.00...</td>\n",
       "      <td>0.090159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On 6 February 2023, at 04:17 TRT (01:17 UTC), ...</td>\n",
       "      <td>[-0.00792725 -0.01488955 -0.01365658 ... -0.00...</td>\n",
       "      <td>0.116934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Immediately after the earthquakes the Turkish ...</td>\n",
       "      <td>[-0.0144761  -0.02395907 -0.00486731 ...  0.01...</td>\n",
       "      <td>0.122007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>The Turkish Government was criticized on socia...</td>\n",
       "      <td>[-0.00442697  0.00012691 -0.00424572 ... -0.00...</td>\n",
       "      <td>0.122824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Mahase, Elisabeth (7 February 2023). \"Death to...</td>\n",
       "      <td>[-0.01114416 -0.0232568  -0.0060126  ...  0.00...</td>\n",
       "      <td>0.123806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01765627 -0.02742681 -0.0249322  ... -0.01...</td>\n",
       "      <td>0.295954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01765627 -0.02742681 -0.0249322  ... -0.01...</td>\n",
       "      <td>0.295954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01765627 -0.02742681 -0.0249322  ... -0.01...</td>\n",
       "      <td>0.295954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01765627 -0.02742681 -0.0249322  ... -0.01...</td>\n",
       "      <td>0.295954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01765627 -0.02742681 -0.0249322  ... -0.01...</td>\n",
       "      <td>0.295954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "3    The confirmed death toll in Turkey was 53,537;...   \n",
       "0    On 6 February 2023, at 04:17 TRT (01:17 UTC), ...   \n",
       "88   Immediately after the earthquakes the Turkish ...   \n",
       "145  The Turkish Government was criticized on socia...   \n",
       "184  Mahase, Elisabeth (7 February 2023). \"Death to...   \n",
       "..                                                 ...   \n",
       "71                                              \\t\\t\\t   \n",
       "64                                              \\t\\t\\t   \n",
       "63                                              \\t\\t\\t   \n",
       "67                                              \\t\\t\\t   \n",
       "76                                              \\t\\t\\t   \n",
       "\n",
       "                                            embeddings  distances  \n",
       "3    [ 0.00134106 -0.02500695 -0.01328005 ...  0.00...   0.090159  \n",
       "0    [-0.00792725 -0.01488955 -0.01365658 ... -0.00...   0.116934  \n",
       "88   [-0.0144761  -0.02395907 -0.00486731 ...  0.01...   0.122007  \n",
       "145  [-0.00442697  0.00012691 -0.00424572 ... -0.00...   0.122824  \n",
       "184  [-0.01114416 -0.0232568  -0.0060126  ...  0.00...   0.123806  \n",
       "..                                                 ...        ...  \n",
       "71   [-0.01765627 -0.02742681 -0.0249322  ... -0.01...   0.295954  \n",
       "64   [-0.01765627 -0.02742681 -0.0249322  ... -0.01...   0.295954  \n",
       "63   [-0.01765627 -0.02742681 -0.0249322  ... -0.01...   0.295954  \n",
       "67   [-0.01765627 -0.02742681 -0.0249322  ... -0.01...   0.295954  \n",
       "76   [-0.01765627 -0.02742681 -0.0249322  ... -0.01...   0.295954  \n",
       "\n",
       "[199 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"distances.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757505cb",
   "metadata": {},
   "source": [
    "## TODO 1: Build the Custom Text Prompt\n",
    "\n",
    "Run the cell below as-is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c16528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# Create a tokenizer that is designed to align with our embeddings\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "token_limit = 1000\n",
    "USER_QUESTION = \"\"\"What were the estimated damages of the 2023 \\\n",
    "Turkey-Syria earthquake?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c0ca1",
   "metadata": {},
   "source": [
    "Now your task is to compose the custom text prompt.\n",
    "\n",
    "The overall structure of the prompt should look like this:\n",
    "\n",
    "```\n",
    "Answer the question based on the context below, and if the\n",
    "question can't be answered based on the context, say \"I don't\n",
    "know\"\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "```\n",
    "\n",
    "In the place marked `context`, provide as much information from `df['text']` as possible without exceeding `token_limit`. In the place marked `question`, add `USER_QUESTION`.\n",
    "\n",
    "Your overall goal is to create a string called `prompt` that contains all of the relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de013ac",
   "metadata": {},
   "source": [
    "If you're getting stuck, you can click to reveal the solution then copy and paste this into the cell below.\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "    <summary style=\"cursor: pointer\"><strong>Solution (click to show/hide)</strong></summary>\n",
    "\n",
    "```python\n",
    "# Count the number of tokens in the prompt template and question\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the \n",
    "question can't be answered based on the context, say \n",
    "\"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                        len(tokenizer.encode(USER_QUESTION))\n",
    "\n",
    "# Create a list to store text for context\n",
    "context_list = []\n",
    "\n",
    "# Loop over rows of the sorted dataframe\n",
    "for text in df[\"text\"].values:\n",
    "    \n",
    "    # Append text to context_list if there is enough room\n",
    "    token_count += len(tokenizer.encode(text))\n",
    "    if token_count <= token_limit:\n",
    "        context_list.append(text)\n",
    "    else:\n",
    "        # Break once we're over the token limit\n",
    "        break\n",
    "\n",
    "# Use string formatting to complete the prompt\n",
    "prompt = prompt_template.format(\n",
    "    \"\\n\\n###\\n\\n\".join(context_list),\n",
    "    USER_QUESTION\n",
    ")\n",
    "print(prompt)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06acf260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the \n",
      "question can't be answered based on the context, say \n",
      "\"I don't know\"\n",
      "\n",
      "Context: \n",
      "\n",
      "The confirmed death toll in Turkey was 53,537; estimates of the number of dead in Syria were between 5,951 and 8,476. It is the deadliest earthquake in what is now present-day Turkey since the 526 Antioch earthquake and the deadliest natural disaster in its modern history. It is also the deadliest in present-day Syria since the 1822 Aleppo earthquake; the deadliest worldwide since the 2010 Haiti earthquake; and the fifth-deadliest of the 21st century. Damages were estimated at US$148.8 billion in Turkey, or nine-percent of the country's GDP, and US$14.8 billion in Syria.\n",
      "\n",
      "###\n",
      "\n",
      "On 6 February 2023, at 04:17 TRT (01:17 UTC), a Mw 7.8 earthquake struck southern and central Turkey and northern and western Syria. The epicenter was 37 km (23 mi) westâ€“northwest of Gaziantep. The earthquake had a maximum Mercalli intensity of XII (Extreme) around the epicenter and in Antakya. It was followed by a Mwâ€¯7.7 earthquake at 13:24. This earthquake was centered 95 km (59 mi) north-northeast from the first. There was widespread damage and tens of thousands of fatalities.\n",
      "\n",
      "###\n",
      "\n",
      "Immediately after the earthquakes the Turkish lira value struck a record low of 18.85 against the US dollar, but rebounded to its starting position at the end of the day. Turkish stock markets fell; main equities benchmark fell as much as 5 percent and banks fell 5.5 percent but recovered from the losses. The country's main stock market dropped 1.35 percent on 6 February. The Borsa Istanbul fell 8.6 percent on 7 February, and declined by more than 7 percent on the morning of 8 February before trading was suspended; the exchange then announced it would close for five days. When the exchange reopened, Turkey's stock soared nearly 10 percent while the lira fell to a record low of 18.9010 against the dollar. Total cost of earthquake damage in Turkey was estimated by TÃœRKONFED at $84.1 billion US dollars; $70.75 billion on rebuilding, $10.4 billion loss in national income, and an additional $2.91 billion loss in workforce. Turkish president Recep Tayyip Erdogan said rebuilding would cost $105 billion. The European Bank for Reconstruction and Development said potential losses may be up to 1 percent of Turkey's GDP in 2023. The Turkish government released a preliminary report estimating the total damage cost at $103.6 billion; corresponding to 9 percent of its GDP in 2023. About half of residential property in the affected area is thought to be covered by Compulsory Earthquake Insurance.\n",
      "\n",
      "###\n",
      "\n",
      "The Turkish Government was criticized on social media for allegedly trying to cover up the fact that there were not two, but three mainshocks above Mwâ€¯7. However, professor Hasan SÃ¶zbilir, Director of Dokuz EylÃ¼l University (DEU) Earthquake Research and Application Center, told Anadolu Agency that there were only 2 mainshocks reaching above Mwâ€¯7 between 6 and 17 February 2023, but of the smaller quakes, there was one that reached Mwâ€¯6.7. Additional allegations were made when the death toll in Turkey was at 41,000, could in fact be up to five times higher. The Justice and Development Party (AKP) government was accused of manipulating the death toll of the earthquakes to mask the scale of the disaster amid growing criticism due to what many say was a delayed and ineffective response to the tragedy.\n",
      "\n",
      "###\n",
      "\n",
      "Mahase, Elisabeth (7 February 2023). \"Death toll rises after two earthquakes hit Turkey and Syria in 12 hours\" (PDF). BMJ. 380 (380): 304. doi:10.1136/bmj.p304. PMID 36750243. S2CID 256630400.\n",
      "\n",
      "---\n",
      "\n",
      "Question: What were the estimated damages of the 2023 Turkey-Syria earthquake?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# Count the number of tokens in the prompt template and question\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the \n",
    "question can't be answered based on the context, say \n",
    "\"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "token_count = len(tokenizer.encode(prompt_template)) + len(tokenizer.encode(USER_QUESTION))\n",
    "\n",
    "# Create a list to store text for context\n",
    "context_list = []\n",
    "\n",
    "# Loop over rows of the sorted dataframe\n",
    "for text in df[\"text\"].values:\n",
    "    token_count += len(tokenizer.encode(text))\n",
    "    # Append text to context_list if there is enough room\n",
    "    if token_count <= token_limit:\n",
    "        context_list.append(text)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Use string formatting to complete the prompt\n",
    "prompt = prompt_template.format(\n",
    "    \"\\n\\n###\\n\\n\".join(context_list),\n",
    "    USER_QUESTION\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097f24d",
   "metadata": {},
   "source": [
    "## TODO 2: Send Custom Text Prompt to Completion Model\n",
    "\n",
    "Using the `prompt` string you created, query an OpenAI `Completion` model to get an answer. Specify a `max_tokens` of 150.\n",
    "\n",
    "If you're getting stuck, you can click to reveal the solution then copy and paste this into the cell below.\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "    <summary style=\"cursor: pointer\"><strong>Solution (click to show/hide)</strong></summary>\n",
    "\n",
    "```python\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "response = openai.Completion.create(\n",
    "    model=COMPLETION_MODEL_NAME,\n",
    "    prompt=prompt,\n",
    "    max_tokens=150\n",
    ")\n",
    "answer = response[\"choices\"][0][\"text\"].strip()\n",
    "print(answer)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b35a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated damages were US$148.8 billion in Turkey and US$14.8 billion in Syria.\n"
     ]
    }
   ],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "response = openai.Completion.create(model=COMPLETION_MODEL_NAME, prompt=prompt, max_tokens=150, logprobs=5, top_p=0.01)\n",
    "answer = response['choices'][0][\"text\"].strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca19340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-9dGOuKEWlsTg3xsazWnygbGSHGnFu at 0x15d5d3d10> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": {\n",
       "        \"text_offset\": [\n",
       "          3726,\n",
       "          3730,\n",
       "          3740,\n",
       "          3748,\n",
       "          3753,\n",
       "          3756,\n",
       "          3757,\n",
       "          3760,\n",
       "          3761,\n",
       "          3762,\n",
       "          3770,\n",
       "          3773,\n",
       "          3780,\n",
       "          3784,\n",
       "          3787,\n",
       "          3788,\n",
       "          3790,\n",
       "          3791,\n",
       "          3792,\n",
       "          3800,\n",
       "          3803,\n",
       "          3809\n",
       "        ],\n",
       "        \"token_logprobs\": [\n",
       "          -0.8970265,\n",
       "          -0.16500674,\n",
       "          -0.015015941,\n",
       "          -0.55660945,\n",
       "          -0.48361897,\n",
       "          -0.0091695525,\n",
       "          -0.017323367,\n",
       "          -3.0471343e-05,\n",
       "          -7.9940866e-05,\n",
       "          -0.00016504127,\n",
       "          -0.0021435972,\n",
       "          -6.5278815e-05,\n",
       "          -0.0513892,\n",
       "          -0.00021772196,\n",
       "          -0.00042066345,\n",
       "          -0.0009349247,\n",
       "          -3.5120287e-05,\n",
       "          -0.00010676169,\n",
       "          -0.00038443657,\n",
       "          -0.00012856863,\n",
       "          -0.000121542944,\n",
       "          -0.009917577\n",
       "        ],\n",
       "        \"tokens\": [\n",
       "          \" The\",\n",
       "          \" estimated\",\n",
       "          \" damages\",\n",
       "          \" were\",\n",
       "          \" US\",\n",
       "          \"$\",\n",
       "          \"148\",\n",
       "          \".\",\n",
       "          \"8\",\n",
       "          \" billion\",\n",
       "          \" in\",\n",
       "          \" Turkey\",\n",
       "          \" and\",\n",
       "          \" US\",\n",
       "          \"$\",\n",
       "          \"14\",\n",
       "          \".\",\n",
       "          \"8\",\n",
       "          \" billion\",\n",
       "          \" in\",\n",
       "          \" Syria\",\n",
       "          \".\"\n",
       "        ],\n",
       "        \"top_logprobs\": [\n",
       "          {\n",
       "            \"\\n\": -2.4310308,\n",
       "            \" $\": -4.212975,\n",
       "            \" Dam\": -1.101294,\n",
       "            \" The\": -0.8970265,\n",
       "            \" US\": -2.5225701\n",
       "          },\n",
       "          {\n",
       "            \" Turkish\": -8.0831375,\n",
       "            \" damage\": -6.9461346,\n",
       "            \" damages\": -1.9533101,\n",
       "            \" estimated\": -0.16500674,\n",
       "            \" total\": -4.8298225\n",
       "          },\n",
       "          {\n",
       "            \" cost\": -6.3501906,\n",
       "            \" costs\": -8.63181,\n",
       "            \" damage\": -4.47706,\n",
       "            \" damages\": -0.015015941,\n",
       "            \" total\": -6.5057025\n",
       "          },\n",
       "          {\n",
       "            \" for\": -4.368961,\n",
       "            \" from\": -6.1482444,\n",
       "            \" in\": -1.8236516,\n",
       "            \" of\": -1.3864968,\n",
       "            \" were\": -0.55660945\n",
       "          },\n",
       "          {\n",
       "            \" \": -5.4227514,\n",
       "            \" $\": -1.0914128,\n",
       "            \" US\": -0.48361897,\n",
       "            \" USD\": -6.3511305,\n",
       "            \" at\": -3.3627923\n",
       "          },\n",
       "          {\n",
       "            \" \": -9.975324,\n",
       "            \" $\": -4.706435,\n",
       "            \"$\": -0.0091695525,\n",
       "            \"$$\": -12.168855,\n",
       "            \"\\\\$\": -11.723264\n",
       "          },\n",
       "          {\n",
       "            \" \": -5.925809,\n",
       "            \"103\": -6.5535707,\n",
       "            \"148\": -0.017323367,\n",
       "            \"70\": -8.221896,\n",
       "            \"84\": -4.446666\n",
       "          },\n",
       "          {\n",
       "            \" billion\": -12.287312,\n",
       "            \",\": -11.010424,\n",
       "            \".\": -3.0471343e-05,\n",
       "            \"8\": -13.575626,\n",
       "            \"<|endoftext|>\": -13.074831\n",
       "          },\n",
       "          {\n",
       "            \"6\": -12.064291,\n",
       "            \"8\": -7.9940866e-05,\n",
       "            \"80\": -11.364616,\n",
       "            \"85\": -12.025293,\n",
       "            \"9\": -11.236048\n",
       "          },\n",
       "          {\n",
       "            \" Billion\": -11.104665,\n",
       "            \" and\": -10.359935,\n",
       "            \" billion\": -0.00016504127,\n",
       "            \" in\": -9.773187,\n",
       "            \" million\": -10.891553\n",
       "          },\n",
       "          {\n",
       "            \" and\": -9.4188385,\n",
       "            \" dollars\": -9.318892,\n",
       "            \" for\": -6.3087096,\n",
       "            \" in\": -0.0021435972,\n",
       "            \".\": -9.396593\n",
       "          },\n",
       "          {\n",
       "            \" Syria\": -12.683086,\n",
       "            \" Tur\": -11.880606,\n",
       "            \" Turkey\": -6.5278815e-05,\n",
       "            \" turkey\": -10.858025,\n",
       "            \"Turkey\": -10.895561\n",
       "          },\n",
       "          {\n",
       "            \" (\": -7.6863036,\n",
       "            \" and\": -0.0513892,\n",
       "            \" or\": -9.560855,\n",
       "            \",\": -3.0167365,\n",
       "            \".\": -7.523088\n",
       "          },\n",
       "          {\n",
       "            \"\\n\": -11.186428,\n",
       "            \" \": -10.91777,\n",
       "            \" $\": -8.943869,\n",
       "            \" US\": -0.00021772196,\n",
       "            \"US\": -10.60438\n",
       "          },\n",
       "          {\n",
       "            \" \": -11.6461935,\n",
       "            \" $\": -7.974435,\n",
       "            \"$\": -0.00042066345,\n",
       "            \"10\": -11.943002,\n",
       "            \"14\": -10.72285\n",
       "          },\n",
       "          {\n",
       "            \" \": -7.6449437,\n",
       "            \"10\": -8.920038,\n",
       "            \"14\": -0.0009349247,\n",
       "            \"70\": -9.428005,\n",
       "            \"84\": -9.373743\n",
       "          },\n",
       "          {\n",
       "            \",\": -10.871303,\n",
       "            \".\": -3.5120287e-05,\n",
       "            \"..\": -13.279035,\n",
       "            \"/\": -12.925593,\n",
       "            \"<|endoftext|>\": -12.7497\n",
       "          },\n",
       "          {\n",
       "            \"4\": -11.504093,\n",
       "            \"7\": -11.204485,\n",
       "            \"8\": -0.00010676169,\n",
       "            \"80\": -11.612791,\n",
       "            \"9\": -10.93354\n",
       "          },\n",
       "          {\n",
       "            \" bil\": -10.358605,\n",
       "            \" billion\": -0.00038443657,\n",
       "            \" in\": -8.228168,\n",
       "            \" million\": -10.347085,\n",
       "            \"b\": -11.13063\n",
       "          },\n",
       "          {\n",
       "            \" In\": -12.217553,\n",
       "            \" Syria\": -10.071418,\n",
       "            \" in\": -0.00012856863,\n",
       "            \".\": -10.696067,\n",
       "            \"in\": -10.811881\n",
       "          },\n",
       "          {\n",
       "            \" S\": -12.412148,\n",
       "            \" Sy\": -9.628716,\n",
       "            \" Syria\": -0.000121542944,\n",
       "            \" Syrian\": -11.822228,\n",
       "            \"Sy\": -10.566108\n",
       "          },\n",
       "          {\n",
       "            \" according\": -8.391349,\n",
       "            \",\": -4.829515,\n",
       "            \".\": -0.009917577,\n",
       "            \".\\n\": -6.507547,\n",
       "            \"<|endoftext|>\": -10.372148\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"text\": \" The estimated damages were US$148.8 billion in Turkey and US$14.8 billion in Syria.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1719144864,\n",
       "  \"id\": \"cmpl-9dGOuKEWlsTg3xsazWnygbGSHGnFu\",\n",
       "  \"model\": \"gpt-3.5-turbo-instruct\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 22,\n",
       "    \"prompt_tokens\": 895,\n",
       "    \"total_tokens\": 917\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70191209",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations ðŸŽ‰\n",
    "\n",
    "You have now completed the prompt engineering process using unsupervised ML to get a custom answer from an OpenAI model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
