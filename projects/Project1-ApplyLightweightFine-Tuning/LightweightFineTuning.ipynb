{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "From the page https://stevhliu-peft-methods.hf.space/ is selcted the combination Lora and gpt-2 (Performance and Ressources)\n",
    "For the dataset i choose the imdb database\n",
    "* PEFT technique: Lora\n",
    "* Model: gpt-2\n",
    "* Evaluation approach: accuracy \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37805831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "#define device in case of a gpu\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c041d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: \n",
      "BuilderName: parquet\n",
      "ConfigName: plain_text\n",
      "Features: {'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}\n",
      "Datasize: 133202802\n",
      "Datasize: 83446840\n",
      "Contains the following data: ['train', 'test', 'unsupervised']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get information about the dataset\n",
    "from datasets import load_dataset_builder\n",
    "from datasets import get_dataset_split_names\n",
    "\n",
    "#imdb and gpt2\n",
    "model_name = 'gpt2'\n",
    "dataset_name = 'imdb'\n",
    "\n",
    "\n",
    "ds_builder = load_dataset_builder(dataset_name)\n",
    "print(\"Description:\", ds_builder.info.description)\n",
    "print(\"BuilderName:\", ds_builder.info.builder_name)\n",
    "print(\"ConfigName:\", ds_builder.info.config_name)\n",
    "print(\"Features:\",ds_builder.info.features)\n",
    "print(\"Datasize:\", ds_builder.info.dataset_size)\n",
    "print(\"Datasize:\", ds_builder.info.download_size)\n",
    "\n",
    "print(\"Contains the following data:\", get_dataset_split_names(dataset_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db719ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 0\n",
    "TEST = 1\n",
    "#Load test and trainingsdataset\n",
    "splits = {'train':TRAIN, 'test':TEST}\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "dataset : Dataset = load_dataset(dataset_name, split=[*splits.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9527d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test\n",
      "[Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 25000\n",
      "})]\n",
      "0\n",
      "1\n",
      "[Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1500\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1500\n",
      "})]\n",
      "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...', 'label': 1}\n",
      "{'text': \"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\", 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(*splits.keys())\n",
    "print(dataset)\n",
    "\n",
    "#Some example Data from test and train \n",
    "for split in splits.values():\n",
    "    print(split)\n",
    "    dataset[split] = dataset[split].shuffle(seed=42).select(range(1500))\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[TRAIN][0])\n",
    "print(dataset[TEST][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the the tokenizer\n",
    "from transformers import GPT2Tokenizer, AutoTokenizer\n",
    "tokenizer : GPT2Tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "#Takes a long time to find out that there is a pre defined eos token which works. Would be great to mention that in one of the excercises\n",
    "tokenizer.pad_token = tokenizer.eos_token   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31f8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1858, 318, 645, 8695, 379, 477, 1022, 6401, 959, 290, 4415, 5329, 475, 262, 1109, 326, 1111, 389, 1644, 2168, 546, 6590, 6741, 13, 4415, 5329, 3073, 42807, 11, 6401, 959, 3073, 6833, 13, 4415, 5329, 21528, 389, 2407, 2829, 13, 6401, 959, 338, 7110, 389, 1290, 517, 8253, 986, 6401, 959, 3073, 517, 588, 5537, 8932, 806, 11, 611, 356, 423, 284, 4136, 20594, 986, 383, 1388, 2095, 318, 4939, 290, 7650, 78, 11, 475, 423, 366, 27659, 40024, 590, 1911, 4380, 588, 284, 8996, 11, 284, 5052, 11, 284, 13446, 13, 1374, 546, 655, 13226, 30, 40473, 1517, 1165, 11, 661, 3597, 6401, 959, 3073, 1605, 475, 11, 319, 262, 584, 1021, 11, 11810, 484, 4702, 1605, 2168, 357, 10185, 737, 6674, 340, 338, 262, 3303, 11, 393, 262, 4437, 11, 475, 314, 892, 428, 2168, 318, 517, 3594, 621, 1605, 13, 2750, 262, 835, 11, 262, 10544, 389, 1107, 922, 290, 8258, 13, 383, 7205, 318, 407, 31194, 379, 477, 986], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [27, 1671, 1220, 6927, 1671, 11037, 2215, 314, 39391, 7254, 306, 26399, 317, 39255, 4013, 411, 11, 314, 1807, 314, 373, 287, 329, 281, 17774, 2677, 8010, 1621, 290, 286, 1781, 16738, 350, 5036, 733, 263, 373, 287, 340, 11, 523, 644, 714, 467, 2642, 30, 27, 1671, 1220, 6927, 1671, 11037, 16371, 2952, 11, 2158, 11, 314, 6939, 326, 428, 1621, 373, 546, 317, 39255, 3819, 11597, 13769, 655, 4013, 411, 13, 314, 2067, 13774, 290, 3521, 470, 2245, 1566, 890, 706, 262, 3807, 4444, 13, 6952, 345, 12091, 11, 16753, 290, 5302, 344, 6213, 11, 329, 6079, 514, 884, 257, 33138, 11800, 290, 32533, 3807, 0, 6952, 345, 3350, 11, 329, 852, 2950, 290, 42458, 262, 3435, 351, 884, 6795, 290, 25049, 48795, 0, 27, 1671, 1220, 6927, 1671, 11037, 40, 8018, 262, 31900, 6621, 26, 262, 5660, 8272, 6621, 290, 262, 6621, 287, 5601, 498, 13, 314, 8018, 262, 2275, 11350, 13895, 3903, 290, 1521, 339, 373, 612, 290, 788, 262, 9190, 11, 11752, 11752, 262, 9190, 986, 477, 21840, 306, 2826, 13, 314, 635, 8018, 3589, 290, 428, 3807, 373, 281, 4151, 12, 404, 877, 11, 257, 8259, 11, 257, 2863, 284, 1986, 616, 47672, 3872, 290, 3443, 1804, 1223, 546, 340, 13, 314, 4988, 2911, 317, 39255, 4013, 411, 468, 550, 262, 976, 1245, 319, 617, 1854, 503, 612, 29847, 1671, 1220, 6927, 1671, 11037, 6385, 314, 1422, 470, 1833, 1521, 262, 3002, 531, 262, 2646, 373, 546, 15153, 4330, 625, 1956, 532, 9930, 6304, 470, 4330, 1123, 584, 379, 477, 12, 314, 7342, 340, 257, 1218, 640, 13, 3244, 314, 373, 1498, 284, 766, 326, 611, 530, 8020, 470, 5615, 257, 2092, 1621, 11, 530, 561, 3538, 2051, 262, 9721, 739, 14421, 286, 15157, 290, 3252, 290, 262, 2769, 6314, 1022, 262, 15153, 326, 4539, 832, 340, 477, 13, 1320, 318, 3446, 262, 1738, 1521, 661, 287, 2276, 1690, 15677, 262, 3872, 546, 511, 12020, 329, 4554, 29847, 1671, 1220, 6927, 1671, 11037, 1537, 1865, 1194, 1738, 1521, 428, 3807, 318, 523, 2818, 0, 27, 1671, 1220, 6927, 1671, 11037, 40, 836, 470, 1577, 257, 4227, 338, 840, 357, 79, 19917, 616, 4141, 8, 546, 284, 644, 9117, 262, 2677, 8010, 1621, 318, 3940, 13, 1439, 314, 760, 318, 326, 314, 460, 12698, 910, 25, 428, 3807, 468, 3421, 616, 1204, 29847, 1671, 1220, 6927, 1671, 11037, 15597, 510, 262, 922, 670, 3730, 11, 345, 15628, 290, 8410, 787, 257, 3580, 29847, 1671, 1220, 6927, 1671, 11037], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "pad token <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create an example token\n",
    "print(tokenizer(dataset[TRAIN]['text'][0]))\n",
    "print(tokenizer(dataset[TEST]['text'][0]))\n",
    "#Reduce the sampline size to 10000 for reducing time\n",
    "print('pad token', tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0281a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1500\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1500\n",
      "})]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the whole dataset\n",
    "ds_tokenized = {}\n",
    "for split in splits.values():\n",
    "    ds_tokenized[split] = dataset[split].map(lambda example: tokenizer(example['text'],return_tensors='pt', truncation=True, padding=True, max_length=512),batched=True, batch_size=16) #batch small to test on my mps machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1858, 318, 645, 8695, 379, 477, 1022, 6401, 959, 290]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Have a look at the data\n",
    "ds_tokenized[TRAIN][0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019b9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load the model\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "#from transformers import GPT2ForSequenceClassification\n",
    "\n",
    "model : AutoModelForSequenceClassification = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # For converting predictions to strings\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")\n",
    "\n",
    "#Why not mentioned this in one of hour excercises\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Freeze all the parameters of the base model\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/udagen/lib/python3.11/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2677a61a85cc44caa8f00906e72029df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77cb366d2fa4647bd4b3d6bb49c86dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4855251610279083, 'eval_accuracy': 0.7806666666666666, 'eval_runtime': 77.4651, 'eval_samples_per_second': 19.364, 'eval_steps_per_second': 2.427, 'epoch': 1.0}\n",
      "{'train_runtime': 170.1884, 'train_samples_per_second': 8.814, 'train_steps_per_second': 1.105, 'train_loss': 0.6234683990478516, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=188, training_loss=0.6234683990478516, metrics={'train_runtime': 170.1884, 'train_samples_per_second': 8.814, 'train_steps_per_second': 1.105, 'train_loss': 0.6234683990478516, 'epoch': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "#metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        learning_rate=2e-3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=ds_tokenized[TRAIN],\n",
    "    eval_dataset=ds_tokenized[TEST],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bbfeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an eval_accuracy of 0.78 and a loss of 0.48 is not bad for one epoch, let's look if we can improve that with PEFT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a config\n",
    "from peft import LoraConfig, TaskType\n",
    "peft_config = LoraConfig(base_model_name_or_path=model_name, task_type=TaskType.SEQ_CLS,fan_in_fan_out=True, inference_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,448 || all params: 124,737,792 || trainable%: 0.23765692437461133\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "peft_model = get_peft_model(model=model, peft_config=peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/udagen/lib/python3.11/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a822442c4a8b445d8c22ceae97a6f85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa6a7d354aa49eebfb41e9303ddcc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3128744065761566, 'eval_accuracy': 0.88, 'eval_runtime': 81.9719, 'eval_samples_per_second': 18.299, 'eval_steps_per_second': 2.293, 'epoch': 1.0}\n",
      "{'train_runtime': 282.4884, 'train_samples_per_second': 5.31, 'train_steps_per_second': 0.666, 'train_loss': 0.37341016404172206, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=188, training_loss=0.37341016404172206, metrics={'train_runtime': 282.4884, 'train_samples_per_second': 5.31, 'train_steps_per_second': 0.666, 'train_loss': 0.37341016404172206, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./peftresults\",\n",
    "        learning_rate=1e-3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=ds_tokenized[TRAIN],\n",
    "    eval_dataset=ds_tokenized[TEST],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wow an accuracy of 0.88 and an eval_loos of 0.31 thats very good from my point of view and only 1500 of training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54e3166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/udagen/lib/python3.11/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aceda630be348e686d9f7a0582c4fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3128744065761566,\n",
       " 'eval_accuracy': 0.88,\n",
       " 'eval_runtime': 82.3811,\n",
       " 'eval_samples_per_second': 18.208,\n",
       " 'eval_steps_per_second': 2.282}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "peft_model_reloaded = AutoModelForSequenceClassification.from_pretrained(\"peft_model\")\n",
    "peft_model_reloaded.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "peft_trainer_reloaded = Trainer(\n",
    "    model=peft_model_reloaded,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./peft_reloaded_results\",\n",
    "        learning_rate=1e-3,\n",
    "        per_device_eval_batch_size=8,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "    ),\n",
    "    train_dataset=ds_tokenized[TRAIN],\n",
    "    eval_dataset=ds_tokenized[TEST],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "peft_trainer_reloaded.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eae5fe",
   "metadata": {},
   "source": [
    "### Results\n",
    "Compared to the Foundation Model with the values of\n",
    "\n",
    "{'eval_loss': 0.4855251610279083, 'eval_accuracy': 0.7806666666666666, 'eval_runtime': 77.4651, 'eval_samples_per_second': 19.364, 'eval_steps_per_second': 2.427, 'epoch': 1.0}\n",
    "\n",
    "the new model has a much better outcome the only thing surprising me a little bit is that the eval runtime is a little bit slower maybe because of the extra calculation for the LoRa layer\n",
    "\n",
    "{'eval_loss': 0.3128744065761566, 'eval_accuracy': 0.88, 'eval_runtime': 82.3811, 'eval_samples_per_second': 18.208, 'eval_steps_per_second': 2.282}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
