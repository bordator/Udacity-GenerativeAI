{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.37.2\n",
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "print( transformers.__version__ )\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelInfo(id='google-bert/bert-base-uncased', author='google-bert', sha='86b5e0934494bd15c9632b12f734a8a67f723594', created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_modified=datetime.datetime(2024, 2, 19, 11, 6, 12, tzinfo=datetime.timezone.utc), private=False, gated=False, disabled=False, downloads=51939371, likes=1525, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'jax', 'rust', 'coreml', 'onnx', 'safetensors', 'bert', 'fill-mask', 'exbert', 'en', 'dataset:bookcorpus', 'dataset:wikipedia', 'arxiv:1810.04805', 'license:apache-2.0', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='fill-mask', mask_token='[MASK]', card_data={'language': 'en', 'license': 'apache-2.0', 'library_name': None, 'tags': ['exbert'], 'base_model': None, 'datasets': ['bookcorpus', 'wikipedia'], 'metrics': None, 'eval_results': None, 'model_name': None}, widget_data=[{'text': 'Paris is the [MASK] of France.'}, {'text': 'The goal of life is [MASK].'}], model_index=None, config={'architectures': ['BertForMaskedLM'], 'model_type': 'bert', 'tokenizer_config': {}}, transformers_info=TransformersInfo(auto_model='AutoModelForMaskedLM', custom_class=None, pipeline_tag='fill-mask', processor='AutoTokenizer'), siblings=[RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='coreml/fill-mask/float32_model.mlpackage/Data/com.apple.CoreML/model.mlmodel', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='coreml/fill-mask/float32_model.mlpackage/Data/com.apple.CoreML/weights/weight.bin', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='coreml/fill-mask/float32_model.mlpackage/Manifest.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='flax_model.msgpack', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='model.onnx', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='pytorch_model.bin', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='rust_model.ot', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='tf_model.h5', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None), RepoSibling(rfilename='vocab.txt', size=None, blob_id=None, lfs=None)], spaces=['microsoft/HuggingGPT', 'Vision-CAIR/minigpt4', 'lnyan/stablediffusion-infinity', 'multimodalart/latentdiffusion', 'Salesforce/BLIP', 'shi-labs/Versatile-Diffusion', 'cvlab/zero123-live', 'AIGC-Audio/AudioGPT', 'xinyu1205/recognize-anything', 'yizhangliu/Grounded-Segment-Anything', 'mrfakename/MeloTTS', 'hilamanor/audioEditing', 'Audio-AGI/AudioSep', 'DAMO-NLP-SG/Video-LLaMA', 'gligen/demo', 'declare-lab/mustango', 'm-ric/chunk_visualizer', 'shgao/EditAnything', 'Vision-CAIR/MiniGPT-v2', 'Awiny/Image2Paragraph', 'Yuliang/ECON', 'IDEA-Research/Grounded-SAM', 'ShilongLiu/Grounding_DINO_demo', 'exbert-project/exbert', 'liuyuan-pal/SyncDreamer', 'haotiz/glip-zeroshot-demo', 'nateraw/lavila', 'Pinwheel/GLIP-BLIP-Object-Detection-VQA', 'Junfeng5/GLEE_demo', 'sam-hq-team/sam-hq', 'abyildirim/inst-inpaint', 'fffiloni/Video-Matting-Anything', 'shi-labs/Matting-Anything', 'eson/tokenizer-arena', 'magicr/BuboGPT', 'OpenGVLab/InternGPT', 'merve/Grounding_DINO_demo', 'clip-italian/clip-italian-demo', 'hongfz16/3DTopia', 'mmlab-ntu/relate-anything-model', 'byeongjun-park/HarmonyView', 'keras-io/bert-semantic-similarity', 'MirageML/sjc', 'NAACL2022/CLIP-Caption-Reward', 'Gladiator/Text-Summarizer', 'ysharma/text-to-image-to-video', 'milyiyo/reimagine-it', 'society-ethics/model-card-regulatory-check', 'linfanluntan/Grounded-SAM', 'yenniejun/tokenizers-languages', 'OpenGVLab/VideoChatGPT', 'fffiloni/miniGPT4-Video-Zero', 'avid-ml/bias-detection', 'llizhx/TinyGPT-V', 'ynhe/AskAnything', 'TencentARC/VLog', 'flax-community/koclip', 'Pusheen/LoCo', 'pseudolab/AI_Tutor_BERT', 'flax-community/clip-reply-demo', 'SeViLA/SeViLA', 'PSLD/PSLD', 'AnimaLab/bias-test-gpt-pairs', 'kaushalya/medclip-roco', 'CosmoAI/BhagwatGeeta', 'thewhole/GaussianDreamer_Demo', 'ALM/CALM', 'sasha/BiasDetection', 'tornadoslims/instruct-pix2pix', 'MykolaL/evp', 'sasha/WinoBiasCheck', 'ccolas/TastyPiano', 'HaloMaster/chinesesummary', 'AIGC-Audio/Make_An_Audio', 'Make-A-Protagonist/Make-A-Protagonist-inference', 'mlpc-lab/BLIVA', 'AILab-CVC/SEED-LLaMA', 'codelion/Grounding_DINO_demo', 'emilylearning/llm_uncertainty', 'fffiloni/audioldm-text-to-audio-generation-copy', 'taesiri/HuggingGPT-Lite', 'Volkopat/SegmentAnythingxGroundingDINO', 'attention-refocusing/Attention-refocusing', 'zdou0830/desco', 'taka-yamakoshi/tokenizer-demo', 'mbahrami/Auto-Complete_Semantic', 'KAIST-Visual-AI-Group/salad-demo', 'EuroPython2022/clickbaitonator', 'doevent/blip', 'RitaParadaRamos/SmallCapDemo', 'Dreamsome/HuggingFace-Datasets-Text-Quality-Analysis', 'badayvedat/AudioSep', 'nsethi610/ns-gradio-apps', 'emilylearning/spurious_correlation_evaluation', 'iakarshu/docformer_for_document_classification', 'webshop/amazon_shop', 'Shredder/CONBERT-3', 'bradarrML/stablediffusion-infinity', 'flax-community/Multilingual-VQA', 'Caoyunkang/Segment-Any-Anomaly'], safetensors=SafeTensorsInfo(parameters={'F32': 110106428}, total=110106428))\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import model_info\n",
    "print(model_info('bert-base-uncased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1386,  0.1583, -0.2967,  ..., -0.2708, -0.2844,  0.4581],\n",
       "         [ 0.5364, -0.2327,  0.1754,  ...,  0.5540,  0.4981, -0.0024],\n",
       "         [ 0.3002, -0.3475,  0.1208,  ..., -0.4562,  0.3288,  0.8773],\n",
       "         ...,\n",
       "         [ 0.3799,  0.1203,  0.8283,  ..., -0.8624, -0.5957,  0.0471],\n",
       "         [-0.0252, -0.7177, -0.6950,  ...,  0.0757, -0.6668, -0.3401],\n",
       "         [ 0.7535,  0.2391,  0.0717,  ...,  0.2467, -0.6458, -0.3213]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9377, -0.5043, -0.9799,  0.9030,  0.9329, -0.2438,  0.8926,  0.2288,\n",
       "         -0.9531, -1.0000, -0.8862,  0.9906,  0.9855,  0.7155,  0.9455, -0.8645,\n",
       "         -0.6035, -0.6666,  0.3020, -0.1587,  0.7455,  1.0000, -0.4022,  0.4261,\n",
       "          0.6151,  0.9996, -0.8773,  0.9594,  0.9585,  0.6950, -0.6718,  0.3325,\n",
       "         -0.9954, -0.2268, -0.9658, -0.9951,  0.6127, -0.7670,  0.0873,  0.0824,\n",
       "         -0.9518,  0.4713,  1.0000,  0.3299,  0.7583, -0.2670, -1.0000,  0.3166,\n",
       "         -0.9364,  0.9910,  0.9719,  0.9893,  0.2190,  0.6048,  0.5849, -0.4123,\n",
       "         -0.0063,  0.1719, -0.3988, -0.6190, -0.6603,  0.5069, -0.9757, -0.9039,\n",
       "          0.9926,  0.9323, -0.3687, -0.4869, -0.3143,  0.0499,  0.9129,  0.3396,\n",
       "         -0.1879, -0.9235,  0.8675,  0.3228, -0.6406,  1.0000, -0.7989, -0.9931,\n",
       "          0.9629,  0.9124,  0.4827, -0.7276,  0.5996, -1.0000,  0.7548, -0.1600,\n",
       "         -0.9941,  0.3386,  0.8394, -0.4158,  0.2943,  0.6111, -0.5745, -0.7185,\n",
       "         -0.4768, -0.9681, -0.4327, -0.6732,  0.1248, -0.2093, -0.5882, -0.4186,\n",
       "          0.5447, -0.6125, -0.6138,  0.4712,  0.4779,  0.7633,  0.3974, -0.4148,\n",
       "          0.7063, -0.9680,  0.7389, -0.4270, -0.9948, -0.6019, -0.9950,  0.7459,\n",
       "         -0.6343, -0.2753,  0.9522, -0.5724,  0.6218, -0.1295, -0.9905, -1.0000,\n",
       "         -0.8710, -0.7506, -0.5008, -0.4827, -0.9872, -0.9847,  0.7214,  0.9694,\n",
       "          0.3013,  1.0000, -0.4427,  0.9699, -0.5431, -0.8189,  0.9180, -0.5132,\n",
       "          0.9026,  0.5274, -0.5940,  0.2928, -0.6933,  0.7179, -0.9318, -0.2776,\n",
       "         -0.9160, -0.9457, -0.3287,  0.9556, -0.7927, -0.9860, -0.1904, -0.2760,\n",
       "         -0.6062,  0.9005,  0.9266,  0.4353, -0.6858,  0.4720,  0.2851,  0.7685,\n",
       "         -0.8647, -0.5626,  0.5127, -0.5468, -0.9490, -0.9907, -0.5809,  0.7146,\n",
       "          0.9948,  0.7981,  0.3463,  0.9349, -0.4238,  0.9333, -0.9754,  0.9936,\n",
       "         -0.2597,  0.4665, -0.5400,  0.4947, -0.8723,  0.0034,  0.8378, -0.9134,\n",
       "         -0.8432, -0.2516, -0.5177, -0.4687, -0.9491,  0.5691, -0.4856, -0.4857,\n",
       "         -0.2245,  0.9609,  0.9823,  0.7496,  0.6256,  0.8552, -0.9073, -0.5802,\n",
       "          0.2874,  0.3017,  0.3016,  0.9974, -0.8503, -0.2108, -0.9261, -0.9907,\n",
       "         -0.0252, -0.9488, -0.3972, -0.8097,  0.8707, -0.7512,  0.8107,  0.5488,\n",
       "         -0.9830, -0.8569,  0.4852, -0.6156,  0.4846, -0.2893,  0.9647,  0.9858,\n",
       "         -0.7064,  0.7120,  0.9593, -0.9590, -0.8708,  0.7893, -0.3561,  0.8603,\n",
       "         -0.7243,  0.9882,  0.9876,  0.9282, -0.9547, -0.8329, -0.7993, -0.8398,\n",
       "         -0.2333,  0.2315,  0.9712,  0.6055,  0.6388,  0.2429, -0.7884,  0.9981,\n",
       "         -0.9448, -0.9804, -0.8184, -0.3534, -0.9951,  0.9729,  0.4165,  0.8094,\n",
       "         -0.6227, -0.8183, -0.9817,  0.8532,  0.1242,  0.9826, -0.6376, -0.9450,\n",
       "         -0.8094, -0.9748,  0.0412, -0.3097, -0.8153, -0.0306, -0.9255,  0.5677,\n",
       "          0.6217,  0.6652, -0.9682,  0.9997,  1.0000,  0.9826,  0.9013,  0.8950,\n",
       "         -1.0000, -0.8081,  1.0000, -0.9995, -1.0000, -0.9361, -0.8200,  0.4755,\n",
       "         -1.0000, -0.2698, -0.0111, -0.9297,  0.8492,  0.9879,  0.9950, -1.0000,\n",
       "          0.8653,  0.9513, -0.5679,  0.9966, -0.6713,  0.9815,  0.6008,  0.7414,\n",
       "         -0.3265,  0.5574, -0.9801, -0.8956, -0.8082, -0.9267,  0.9999,  0.2542,\n",
       "         -0.7970, -0.8854,  0.7831, -0.1391, -0.0060, -0.9786, -0.4503,  0.8895,\n",
       "          0.9021,  0.3021,  0.2650, -0.5750,  0.5099,  0.1216,  0.1170,  0.6484,\n",
       "         -0.9505, -0.3889, -0.6938,  0.2508, -0.7526, -0.9831,  0.9646, -0.2742,\n",
       "          0.9865,  1.0000,  0.3756, -0.9045,  0.8847,  0.4860, -0.5515,  1.0000,\n",
       "          0.9092, -0.9904, -0.4959,  0.7900, -0.7156, -0.8280,  0.9999, -0.4197,\n",
       "         -0.9282, -0.7733,  0.9945, -0.9956,  0.9998, -0.8985, -0.9838,  0.9735,\n",
       "          0.9655, -0.8103, -0.8325,  0.1020, -0.6722,  0.4561, -0.9412,  0.8396,\n",
       "          0.6979, -0.1201,  0.9288, -0.8345, -0.6312,  0.4356, -0.8901, -0.4565,\n",
       "          0.9874,  0.5709, -0.2111, -0.0206, -0.4182, -0.9116, -0.9781,  0.8246,\n",
       "          1.0000, -0.4229,  0.9489, -0.5226, -0.0986,  0.2202,  0.7459,  0.7152,\n",
       "         -0.3528, -0.8800,  0.9299, -0.9716, -0.9949,  0.7278,  0.2206, -0.4944,\n",
       "          1.0000,  0.6285,  0.3795,  0.7228,  0.9993,  0.0301,  0.5936,  0.9816,\n",
       "          0.9914, -0.3465,  0.5882,  0.8365, -0.9824, -0.4488, -0.7612,  0.1331,\n",
       "         -0.9479, -0.0559, -0.9697,  0.9846,  0.9960,  0.5818,  0.3121,  0.8577,\n",
       "          1.0000, -0.9274,  0.6693, -0.1365,  0.8035, -1.0000, -0.8057, -0.4504,\n",
       "         -0.1711, -0.9512, -0.5899,  0.3991, -0.9754,  0.9563,  0.8806, -0.9937,\n",
       "         -0.9923, -0.4979,  0.8853,  0.1439, -0.9994, -0.8986, -0.6272,  0.8385,\n",
       "         -0.3239, -0.9470, -0.7009, -0.4768,  0.5742, -0.2216,  0.5665,  0.9667,\n",
       "          0.7935, -0.9401, -0.6746, -0.1753, -0.9163,  0.9409, -0.8701, -0.9894,\n",
       "         -0.2514,  1.0000, -0.4087,  0.9385,  0.6050,  0.8219, -0.2712,  0.3326,\n",
       "          0.9827,  0.3613, -0.8314, -0.9850, -0.2861, -0.5398,  0.8254,  0.8414,\n",
       "          0.7590,  0.9412,  0.9627,  0.2765, -0.0737,  0.0399,  0.9998, -0.3095,\n",
       "         -0.1933, -0.4689, -0.2511, -0.4629, -0.2914,  1.0000,  0.3963,  0.7777,\n",
       "         -0.9950, -0.9808, -0.9303,  1.0000,  0.8822, -0.6848,  0.8124,  0.6242,\n",
       "         -0.2551,  0.8266, -0.2791, -0.3167,  0.2294,  0.1682,  0.9627, -0.6738,\n",
       "         -0.9904, -0.7910,  0.7099, -0.9770,  1.0000, -0.7030, -0.3960, -0.5981,\n",
       "         -0.6683, -0.2727, -0.0183, -0.9882, -0.3841,  0.5605,  0.9745,  0.3505,\n",
       "         -0.4898, -0.9298,  0.9578,  0.9533, -0.9859, -0.9597,  0.9777, -0.9784,\n",
       "          0.7550,  1.0000,  0.3446,  0.6786,  0.3947, -0.5349,  0.5541, -0.6754,\n",
       "          0.8078, -0.9595, -0.4484, -0.3901,  0.3983, -0.1319, -0.2896,  0.7860,\n",
       "          0.3500, -0.5530, -0.7294, -0.2361,  0.4663,  0.9332, -0.3048, -0.1916,\n",
       "          0.2318, -0.3230, -0.9323, -0.4672, -0.6315, -1.0000,  0.8068, -1.0000,\n",
       "          0.8035,  0.4066, -0.3700,  0.8760,  0.7829,  0.8298, -0.8628, -0.9795,\n",
       "          0.1322,  0.8529, -0.5029, -0.9057, -0.6918,  0.5017, -0.2052,  0.1564,\n",
       "         -0.7397,  0.8156, -0.3414,  1.0000,  0.2659, -0.8292, -0.9821,  0.2491,\n",
       "         -0.3009,  1.0000, -0.8952, -0.9832,  0.3330, -0.9180, -0.8493,  0.5868,\n",
       "          0.1653, -0.8522, -0.9961,  0.9220,  0.8661, -0.6477,  0.7927, -0.3991,\n",
       "         -0.7691,  0.1512,  0.9868,  0.9924,  0.7317,  0.9083, -0.1226, -0.5258,\n",
       "          0.9840,  0.4009, -0.0436,  0.1361,  1.0000,  0.4004, -0.9497, -0.1309,\n",
       "         -0.9788, -0.3522, -0.9551,  0.3755,  0.3099,  0.9195, -0.4460,  0.9738,\n",
       "         -0.9714,  0.1901, -0.8894, -0.7863,  0.4757, -0.9463, -0.9892, -0.9938,\n",
       "          0.8142, -0.4077, -0.1895,  0.2102,  0.1715,  0.6322,  0.5566, -1.0000,\n",
       "          0.9642,  0.6150,  0.9768,  0.9768,  0.9115,  0.8108,  0.3251, -0.9920,\n",
       "         -0.9910, -0.5438, -0.3567,  0.7960,  0.7648,  0.8900,  0.6470, -0.4875,\n",
       "         -0.4792, -0.7756, -0.8423, -0.9972,  0.5961, -0.8679, -0.9678,  0.9718,\n",
       "         -0.3461, -0.1534, -0.2139, -0.9586,  0.9321,  0.7627,  0.4636,  0.0862,\n",
       "          0.5071,  0.9170,  0.9597,  0.9882, -0.9231,  0.8555, -0.9196,  0.6712,\n",
       "          0.9381, -0.9606,  0.2335,  0.8301, -0.5560,  0.3696, -0.4752, -0.9740,\n",
       "          0.8174, -0.4268,  0.7773, -0.4798,  0.0639, -0.4718, -0.2607, -0.7624,\n",
       "         -0.8742,  0.6576,  0.6207,  0.9219,  0.9360, -0.0496, -0.8942, -0.3701,\n",
       "         -0.8944, -0.9526,  0.9536, -0.0851, -0.2961,  0.9031,  0.1321,  0.9324,\n",
       "          0.4289, -0.4989, -0.4174, -0.7639,  0.8887, -0.7894, -0.7639, -0.7093,\n",
       "          0.8105,  0.3595,  1.0000, -0.9188, -0.9878, -0.8268, -0.6012,  0.4992,\n",
       "         -0.7880, -1.0000,  0.3609, -0.8314,  0.8524, -0.9398,  0.9500, -0.9339,\n",
       "         -0.9851, -0.3495,  0.8436,  0.9375, -0.5159, -0.8989,  0.5196, -0.8797,\n",
       "          0.9979,  0.8753, -0.8277, -0.0012,  0.6013, -0.9184, -0.7398,  0.9228]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'heart', 'genera', '##tive', 'ai']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"I heart Generative AI\")\n",
    "inputs = tokenizer(\"I heart Generative AI\", return_tensors=\"pt\")\n",
    "# Print the tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 2540, 11416, 6024, 9932]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "test = F.softmax(torch.Tensor(), dim=0)\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_input = tokenizer(\"I am\", return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0062,  0.3906,  0.0563,  ...,  0.0102,  0.2153,  0.1564],\n",
       "         [-0.0828,  0.3103,  0.3317,  ..., -0.1004,  0.6044,  0.1337],\n",
       "         [ 0.0556, -0.2650, -0.0133,  ...,  0.5204,  0.8981, -0.0643],\n",
       "         [ 0.7994,  0.0725, -0.2555,  ...,  0.0236, -0.5920, -0.2448]]]), pooler_output=tensor([[-8.1386e-01, -2.0925e-01,  6.0658e-01,  6.4754e-01, -3.8358e-01,\n",
       "         -1.1094e-01,  8.3306e-01,  1.2227e-01,  2.6253e-01, -9.9926e-01,\n",
       "          2.7122e-01,  6.1773e-02,  9.6340e-01, -1.8702e-01,  8.8314e-01,\n",
       "         -4.2935e-01, -1.7535e-01, -4.5818e-01,  3.1444e-01, -7.5042e-01,\n",
       "          5.1547e-01,  5.9268e-01,  6.0282e-01,  1.7881e-01,  2.8890e-01,\n",
       "          1.1605e-01, -4.2012e-01,  8.8301e-01,  9.2191e-01,  5.9869e-01,\n",
       "         -6.4658e-01,  5.4834e-02, -9.7021e-01, -1.0000e-01,  4.7549e-01,\n",
       "         -9.6636e-01,  1.3665e-01, -6.7730e-01,  9.9874e-02,  1.1805e-01,\n",
       "         -8.3735e-01,  1.1698e-01,  9.8953e-01, -2.5578e-01, -6.5723e-02,\n",
       "         -2.0431e-01, -9.9900e-01,  1.7153e-01, -8.1756e-01, -4.5782e-01,\n",
       "         -3.6877e-01, -6.5134e-01,  9.7935e-02,  2.9548e-01,  3.2960e-01,\n",
       "          3.9851e-01, -1.4170e-01,  8.2377e-02, -7.3000e-02, -4.4829e-01,\n",
       "         -5.3416e-01,  2.3058e-01,  2.5729e-01, -8.3333e-01, -4.2460e-01,\n",
       "         -5.0200e-01,  1.2002e-02, -1.2637e-01,  3.6825e-02, -7.6820e-02,\n",
       "          7.2247e-01,  1.3775e-01,  4.3153e-01, -7.0632e-01, -4.9061e-01,\n",
       "          6.2263e-02, -3.7955e-01,  9.9997e-01, -4.0516e-01, -9.5414e-01,\n",
       "         -5.2006e-01, -3.3906e-01,  2.6618e-01,  5.9974e-01, -5.1467e-01,\n",
       "         -9.9982e-01,  1.6735e-01, -2.9866e-02, -9.7733e-01,  1.1059e-01,\n",
       "          1.9052e-01, -1.2589e-01, -5.8243e-01,  3.1261e-01, -7.4297e-02,\n",
       "         -3.2124e-02, -1.9126e-01,  4.4807e-01, -5.2186e-02,  6.2242e-02,\n",
       "         -2.2472e-02, -1.1958e-01,  9.7145e-02, -2.1949e-01,  2.2574e-02,\n",
       "         -2.4287e-01, -4.6076e-01,  1.9311e-01, -2.2031e-01,  5.3627e-01,\n",
       "          2.4290e-01, -1.9414e-01,  1.7041e-01, -9.1753e-01,  5.1035e-01,\n",
       "         -1.2719e-01, -9.5851e-01, -3.2916e-01, -9.7046e-01,  5.9439e-01,\n",
       "          1.7189e-01,  5.6988e-03,  9.3175e-01,  6.0075e-01,  1.9489e-01,\n",
       "          7.6457e-02,  4.3939e-01, -9.9999e-01, -2.6226e-01, -2.4483e-04,\n",
       "          3.2049e-01, -1.5146e-02, -9.4994e-01, -9.0632e-01,  4.3436e-01,\n",
       "          9.1242e-01,  2.7247e-02,  9.8121e-01, -1.5565e-01,  8.7769e-01,\n",
       "          2.0615e-01,  3.1744e-02, -3.3405e-01, -2.6302e-01,  2.3187e-01,\n",
       "          2.7408e-01, -6.3895e-01,  1.8949e-01,  9.4588e-02, -1.8063e-01,\n",
       "          2.0794e-01, -1.5379e-01,  3.5249e-01, -8.7792e-01, -3.3562e-01,\n",
       "          9.0692e-01,  3.4284e-01,  4.2150e-01,  6.3788e-01, -1.2510e-01,\n",
       "         -2.8604e-01,  7.2352e-01,  1.8084e-01,  2.0937e-01,  5.5594e-02,\n",
       "          2.4181e-01, -2.5840e-01,  3.4362e-01, -7.3656e-01,  3.3707e-01,\n",
       "          3.0455e-01, -1.0429e-01,  4.8388e-01, -9.5198e-01, -1.5771e-01,\n",
       "          2.6750e-01,  9.7327e-01,  6.1363e-01,  1.1148e-01, -5.1030e-02,\n",
       "         -1.6104e-01,  1.9261e-02, -8.8947e-01,  9.5448e-01, -1.2455e-01,\n",
       "          1.8685e-01,  6.5666e-01, -2.9039e-01, -8.4013e-01, -4.8590e-01,\n",
       "          7.3546e-01,  6.8393e-02, -7.9043e-01,  1.2047e-01, -3.9474e-01,\n",
       "         -2.7041e-01,  4.4490e-01,  4.2366e-01, -2.3159e-01, -3.1894e-01,\n",
       "          4.9605e-02,  8.6666e-01,  9.3850e-01,  7.5129e-01, -5.8701e-01,\n",
       "          4.8485e-01, -8.3475e-01, -3.6112e-01,  8.1894e-02,  1.7634e-01,\n",
       "          1.1462e-01,  9.8263e-01,  2.9377e-01, -6.9393e-02, -8.8862e-01,\n",
       "         -9.7055e-01, -1.0214e-02, -8.5180e-01,  1.8806e-02, -5.2752e-01,\n",
       "          8.7994e-02,  7.3635e-01, -1.6332e-01,  3.1319e-01, -9.6815e-01,\n",
       "         -7.3227e-01,  2.6117e-01, -1.3668e-01,  3.1278e-01, -2.1215e-01,\n",
       "          1.7066e-01, -3.7975e-01, -4.4312e-01,  7.9524e-01,  7.9887e-01,\n",
       "          6.0498e-01, -5.9364e-01,  7.7471e-01, -1.5054e-01,  8.2321e-01,\n",
       "         -4.5521e-01,  9.4049e-01, -2.0685e-01,  4.0226e-01, -8.8869e-01,\n",
       "          4.6945e-01, -8.5141e-01,  2.9305e-01, -1.1603e-02, -6.6526e-01,\n",
       "         -3.3915e-01,  2.7950e-01,  1.8696e-01,  8.1608e-01, -3.3406e-01,\n",
       "          9.9075e-01, -2.3326e-01, -9.0900e-01,  6.7432e-01, -5.5470e-02,\n",
       "         -9.7468e-01, -3.3919e-01,  1.2297e-01, -7.1065e-01, -2.0692e-01,\n",
       "         -2.0514e-01, -9.2446e-01,  8.3315e-01,  5.2806e-02,  9.6777e-01,\n",
       "          2.0367e-01, -8.8201e-01, -8.2169e-02, -8.4094e-01, -1.5981e-01,\n",
       "         -5.7487e-02,  6.2306e-01, -1.9628e-01, -9.1203e-01,  3.5715e-01,\n",
       "          4.5698e-01,  2.8626e-01,  6.1763e-01,  9.8752e-01,  9.7833e-01,\n",
       "          9.4874e-01,  8.0640e-01,  7.7999e-01, -3.2705e-01,  3.5328e-01,\n",
       "          9.9965e-01, -2.2468e-01, -9.9917e-01, -9.0547e-01, -3.9923e-01,\n",
       "          2.8511e-01, -9.9998e-01,  1.4186e-02,  1.1299e-01, -8.5524e-01,\n",
       "         -4.1380e-01,  9.6069e-01,  9.7532e-01, -9.9991e-01,  7.7453e-01,\n",
       "          9.0553e-01, -4.0511e-01,  9.5210e-02, -5.7137e-02,  9.4904e-01,\n",
       "          2.3174e-01,  1.7788e-01, -3.5617e-02,  1.9957e-01,  2.6404e-01,\n",
       "         -7.6423e-01,  4.9391e-01,  4.9883e-01, -9.4924e-02,  1.0409e-01,\n",
       "         -5.8334e-01, -8.7432e-01, -2.8090e-01, -3.4040e-02, -2.8827e-01,\n",
       "         -9.2157e-01, -7.1366e-02, -4.7488e-01,  4.8512e-01,  2.9877e-02,\n",
       "          9.2306e-02, -6.7765e-01,  6.7031e-02, -6.6376e-01,  2.8174e-01,\n",
       "          4.4153e-01, -8.6213e-01, -5.4634e-01, -8.4329e-02, -5.0126e-01,\n",
       "          4.1882e-01, -9.0295e-01,  9.4441e-01, -9.6104e-02, -2.7538e-01,\n",
       "          9.9994e-01, -5.2285e-01, -8.0697e-01,  2.1908e-01,  1.4068e-01,\n",
       "          6.5292e-02,  9.9990e-01,  2.8562e-01, -9.5368e-01, -2.7878e-01,\n",
       "          1.2287e-02, -2.2791e-01, -2.9065e-01,  9.9224e-01, -1.3002e-01,\n",
       "          4.4572e-01,  5.1668e-01,  9.3146e-01, -9.7693e-01, -3.1944e-01,\n",
       "         -8.6435e-01, -9.3166e-01,  9.2271e-01,  8.8681e-01,  4.1620e-02,\n",
       "         -4.2469e-01, -2.6103e-02,  2.0189e-01,  1.3729e-01, -9.4027e-01,\n",
       "          4.8976e-01,  4.0982e-01, -1.1613e-01,  8.5896e-01, -7.9985e-01,\n",
       "         -3.4078e-01,  3.3643e-01,  2.5372e-01,  4.6359e-01, -5.0824e-01,\n",
       "          3.0786e-01, -1.7061e-01,  9.3232e-02, -1.4929e-01,  1.7078e-01,\n",
       "         -9.4679e-01, -9.1993e-02,  9.9985e-01,  2.7001e-01, -6.2655e-01,\n",
       "         -1.5589e-01, -1.1757e-02, -3.7286e-01,  2.0210e-01,  2.7914e-01,\n",
       "         -1.9882e-01, -7.3953e-01, -3.1075e-01, -8.8984e-01, -9.6719e-01,\n",
       "          6.3555e-01,  9.8761e-02, -1.8059e-01,  9.9315e-01,  1.1985e-01,\n",
       "          7.5872e-02, -2.6568e-01, -1.3697e-01, -3.5676e-02,  4.2238e-01,\n",
       "         -5.3253e-01,  9.4892e-01, -1.3660e-01,  2.9302e-01,  7.5756e-01,\n",
       "          3.6918e-01, -2.5143e-01, -5.3221e-01,  5.3754e-03, -8.3780e-01,\n",
       "          7.9594e-02, -9.2455e-01,  9.2218e-01, -5.0875e-01,  2.4641e-01,\n",
       "          1.4492e-02, -3.5791e-01,  9.9992e-01,  5.0482e-01,  4.5901e-01,\n",
       "         -5.3423e-01,  8.3785e-01, -2.9982e-01, -6.7485e-01, -2.3355e-01,\n",
       "          5.8684e-02,  5.2539e-01, -1.3205e-01,  1.5848e-01, -9.3744e-01,\n",
       "         -3.6445e-01, -3.7216e-01, -9.6452e-01, -9.7545e-01,  5.9059e-01,\n",
       "          6.9847e-01, -3.6394e-02,  1.6517e-01, -5.7626e-01, -4.8370e-01,\n",
       "          1.0314e-02, -9.3218e-02, -8.9010e-01,  5.8278e-01, -1.5799e-01,\n",
       "          3.3570e-01, -1.2921e-01,  3.5694e-01, -5.2667e-01,  7.7356e-01,\n",
       "          7.2268e-01,  2.7451e-01,  4.4492e-02, -6.8166e-01,  7.2949e-01,\n",
       "         -7.6904e-01,  3.5934e-01, -8.7700e-02,  9.9998e-01, -2.1767e-01,\n",
       "         -2.5113e-01,  6.3450e-01,  6.3927e-01,  6.1667e-03,  1.6387e-01,\n",
       "         -4.3136e-01,  3.7365e-02,  4.9737e-01,  5.2950e-01, -7.7007e-01,\n",
       "         -1.8363e-01,  4.1431e-01, -6.4866e-01, -4.8461e-01,  6.6180e-01,\n",
       "         -2.6762e-01,  4.5099e-02,  1.2336e-01,  2.6727e-02,  9.9660e-01,\n",
       "         -6.5207e-02,  1.7357e-02, -3.5133e-01,  2.3186e-02, -1.6596e-01,\n",
       "         -5.9704e-01,  9.9945e-01,  2.9886e-01, -2.9380e-01, -9.7813e-01,\n",
       "          4.4058e-01, -8.3276e-01,  9.4688e-01,  7.1328e-01, -7.4509e-01,\n",
       "          3.4140e-01,  1.5802e-01, -1.0896e-01,  6.9986e-01, -4.9168e-02,\n",
       "         -1.2562e-01, -1.8009e-02,  4.0705e-02,  9.3695e-01, -2.3969e-01,\n",
       "         -9.2185e-01, -4.1332e-01,  2.1161e-01, -9.3064e-01,  3.6043e-01,\n",
       "         -3.8665e-01, -1.0183e-01, -1.2328e-01,  4.2624e-01,  8.1332e-01,\n",
       "         -4.8743e-02, -9.6079e-01, -8.6470e-02, -6.8640e-02,  9.3394e-01,\n",
       "          9.1013e-02, -3.1650e-01, -8.6317e-01, -6.6233e-01, -2.7785e-01,\n",
       "          5.7137e-01, -8.7211e-01,  9.4425e-01, -9.6822e-01,  2.6178e-01,\n",
       "          9.9962e-01,  1.8617e-01, -7.4362e-01,  3.5861e-02, -3.5592e-01,\n",
       "          1.1870e-01,  3.6609e-01,  5.0110e-01, -9.1008e-01, -1.5013e-01,\n",
       "         -4.7558e-02,  1.5687e-01, -1.4859e-01,  5.0878e-01,  5.2354e-01,\n",
       "          8.6202e-02, -2.8386e-01, -3.8081e-01, -2.3427e-02,  3.0643e-01,\n",
       "          6.0415e-01, -2.0513e-01, -2.7176e-02,  4.7873e-02, -9.4495e-02,\n",
       "         -8.4423e-01, -1.2173e-01, -1.1184e-01, -8.0793e-01,  5.2065e-01,\n",
       "         -9.9996e-01, -5.3412e-01, -5.5965e-01, -2.0633e-01,  7.2605e-01,\n",
       "         -2.1069e-01, -1.6987e-01, -5.9323e-01,  4.0897e-01,  8.1263e-01,\n",
       "          6.2744e-01, -1.4483e-01,  2.0690e-01, -6.1111e-01,  6.6909e-02,\n",
       "          1.0276e-02,  1.4427e-01,  1.9639e-01,  6.6906e-01, -2.4656e-02,\n",
       "          9.9998e-01,  9.0414e-03, -3.9769e-01, -9.4803e-01,  1.5843e-01,\n",
       "         -1.4306e-01,  9.9059e-01, -8.6160e-01, -9.0432e-01,  1.8537e-01,\n",
       "         -2.8341e-01, -7.3711e-01,  1.2704e-01, -4.3288e-02, -4.4526e-01,\n",
       "          2.6006e-01,  9.1786e-01,  8.4314e-01, -3.0131e-01,  3.4701e-01,\n",
       "         -1.8126e-01, -3.4214e-01,  4.1771e-03, -5.8597e-01,  9.6995e-01,\n",
       "         -7.6944e-02,  8.5477e-01,  6.9742e-01,  1.4846e-01,  9.3620e-01,\n",
       "          1.4016e-01,  6.0372e-01,  2.5117e-02,  9.9959e-01,  1.6192e-01,\n",
       "         -8.6563e-01,  4.8235e-01, -9.7253e-01, -3.8700e-02, -9.2283e-01,\n",
       "          1.4309e-01, -3.8331e-02,  8.2559e-01, -1.4661e-01,  9.3366e-01,\n",
       "          6.1426e-01,  6.1526e-02,  2.7889e-01,  5.7650e-01,  1.9363e-01,\n",
       "         -8.6310e-01, -9.6872e-01, -9.7407e-01,  9.1992e-02, -3.1318e-01,\n",
       "         -1.0029e-02,  2.0456e-01,  1.3855e-01,  2.3566e-01,  1.6930e-01,\n",
       "         -9.9910e-01,  8.8536e-01,  2.7195e-01, -4.4421e-01,  9.2433e-01,\n",
       "          4.0802e-02,  5.0676e-02,  8.9174e-02, -9.6936e-01, -9.4394e-01,\n",
       "         -1.8863e-01, -2.0623e-01,  6.6471e-01,  4.6394e-01,  7.9607e-01,\n",
       "          2.1100e-01, -4.1096e-01, -9.2085e-03,  4.7241e-01,  1.9324e-02,\n",
       "         -9.8174e-01,  2.8314e-01,  3.5083e-01, -9.4507e-01,  9.2589e-01,\n",
       "         -5.0901e-01, -1.8815e-01,  6.4413e-01,  4.3416e-01,  8.8429e-01,\n",
       "          6.0062e-01,  4.3543e-01,  9.8035e-02,  3.2078e-01,  8.2958e-01,\n",
       "          9.0399e-01,  9.7382e-01,  3.2232e-01,  7.0262e-01,  3.9504e-01,\n",
       "          2.1404e-01,  1.3499e-01, -8.6412e-01,  3.7762e-02, -1.9274e-01,\n",
       "          6.3955e-02,  8.8264e-02, -9.0188e-02, -9.3225e-01,  1.9378e-01,\n",
       "         -4.2402e-02,  2.8545e-01, -2.5579e-01,  1.9630e-01, -2.8598e-01,\n",
       "         -1.6334e-01, -6.1939e-01, -2.5167e-01,  4.3322e-01,  3.6063e-01,\n",
       "          8.7550e-01, -1.3656e-01,  2.2266e-02, -5.8120e-01, -1.5156e-02,\n",
       "          4.4121e-01, -8.6927e-01,  8.4794e-01,  2.8096e-02,  4.5980e-01,\n",
       "         -3.6142e-01, -7.3032e-02,  1.5093e-01, -4.2196e-01, -2.3443e-01,\n",
       "         -1.7999e-01, -6.6490e-01,  7.6700e-01,  1.0390e-02, -3.4168e-01,\n",
       "         -3.2190e-01,  4.4364e-01,  2.1909e-01,  6.5803e-01,  3.6797e-01,\n",
       "          2.6169e-01,  3.7808e-02, -5.1580e-02,  2.0421e-01, -1.5156e-01,\n",
       "         -9.9915e-01,  3.1589e-01,  3.9686e-01, -3.2005e-01,  2.0854e-01,\n",
       "         -5.2004e-01,  2.1193e-01, -9.4272e-01,  3.0528e-03, -3.2649e-01,\n",
       "         -3.7713e-01, -4.1564e-01, -1.8981e-01,  3.2924e-01,  5.0499e-01,\n",
       "         -2.1425e-01,  8.0470e-01,  2.4213e-01,  6.4919e-01,  4.2409e-01,\n",
       "          5.1343e-01, -5.2733e-01,  8.3065e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
